14:49:52  Running with dbt=1.7.13
14:49:52  Installing dbt-labs/dbt_utils
14:49:53  Installed from version 1.1.1
14:49:53  Updated version available: 1.3.0
14:49:53  
14:49:53  Updates available for packages: ['dbt-labs/dbt_utils']                 
Update your versions in packages.yml, then run dbt deps
14:49:56  Running with dbt=1.7.13
14:49:57  Registered adapter: spark=1.7.1
14:49:57  Found 44 models, 4 tests, 17 sources, 0 exposures, 0 metrics, 553 macros, 0 groups, 0 semantic models
14:49:57  
:: loading settings :: url = jar:file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /root/.ivy2/cache
The jars for the packages stored in: /root/.ivy2/jars
com.databricks#spark-xml_2.12 added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-fc63b2e0-2f71-4560-a266-4ca9c0b42a43;1.0
	confs: [default]
	found com.databricks#spark-xml_2.12;0.17.0 in central
	found commons-io#commons-io;2.11.0 in central
	found org.glassfish.jaxb#txw2;3.0.2 in central
	found org.apache.ws.xmlschema#xmlschema-core;2.3.0 in central
	found org.scala-lang.modules#scala-collection-compat_2.12;2.9.0 in central
:: resolution report :: resolve 530ms :: artifacts dl 38ms
	:: modules in use:
	com.databricks#spark-xml_2.12;0.17.0 from central in [default]
	commons-io#commons-io;2.11.0 from central in [default]
	org.apache.ws.xmlschema#xmlschema-core;2.3.0 from central in [default]
	org.glassfish.jaxb#txw2;3.0.2 from central in [default]
	org.scala-lang.modules#scala-collection-compat_2.12;2.9.0 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   5   |   0   |   0   |   0   ||   5   |   0   |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-fc63b2e0-2f71-4560-a266-4ca9c0b42a43
	confs: [default]
	0 artifacts copied, 5 already retrieved (0kB/23ms)
WARNING: An illegal reflective access operation has occurred
WARNING: Illegal reflective access by org.apache.hadoop.shaded.org.xbill.DNS.ResolverConfig (file:/usr/local/lib/python3.8/dist-packages/pyspark/jars/hadoop-client-runtime-3.3.2.jar) to method sun.net.dns.ResolverConfiguration.open()
WARNING: Please consider reporting this to the maintainers of org.apache.hadoop.shaded.org.xbill.DNS.ResolverConfig
WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations
WARNING: All illegal access operations will be denied in a future release
25/01/19 14:50:02 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/01/19 14:50:09 WARN DomainSocketFactory: The short-circuit local reads feature cannot be used because libhadoop cannot be loaded.
25/01/19 14:50:09 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.
25/01/19 14:50:18 WARN Client: Same path resource file:///root/.ivy2/jars/com.databricks_spark-xml_2.12-0.17.0.jar added multiple times to distributed cache.
25/01/19 14:50:18 WARN Client: Same path resource file:///root/.ivy2/jars/commons-io_commons-io-2.11.0.jar added multiple times to distributed cache.
25/01/19 14:50:18 WARN Client: Same path resource file:///root/.ivy2/jars/org.glassfish.jaxb_txw2-3.0.2.jar added multiple times to distributed cache.
25/01/19 14:50:18 WARN Client: Same path resource file:///root/.ivy2/jars/org.apache.ws.xmlschema_xmlschema-core-2.3.0.jar added multiple times to distributed cache.
25/01/19 14:50:18 WARN Client: Same path resource file:///root/.ivy2/jars/org.scala-lang.modules_scala-collection-compat_2.12-2.9.0.jar added multiple times to distributed cache.
25/01/19 14:50:40 WARN HiveClientImpl: Detected HiveConf hive.execution.engine is 'tez' and will be reset to 'mr' to disable useless hive logic
14:50:44  Concurrency: 1 threads (target='dev')
14:50:44  
14:50:44  1 of 43 START sql table model demo_bronze.brokerage_cash_transaction ........... [RUN]
25/01/19 14:50:45 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
25/01/19 14:50:45 WARN SessionState: METASTORE_FILTER_HOOK will be ignored, since hive.security.authorization.manager is set to instance of HiveAuthorizerFactory.
14:51:44  1 of 43 OK created sql table model demo_bronze.brokerage_cash_transaction ...... [OK in 60.66s]
14:51:44  2 of 43 START sql table model demo_bronze.brokerage_daily_market ............... [RUN]
25/01/19 14:51:45 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:54:11  2 of 43 OK created sql table model demo_bronze.brokerage_daily_market .......... [OK in 146.23s]
14:54:11  3 of 43 START sql table model demo_bronze.brokerage_holding_history ............ [RUN]
25/01/19 14:54:11 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:54:31  3 of 43 OK created sql table model demo_bronze.brokerage_holding_history ....... [OK in 20.17s]
14:54:31  4 of 43 START sql table model demo_bronze.brokerage_trade ...................... [RUN]
25/01/19 14:54:31 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:55:47  4 of 43 OK created sql table model demo_bronze.brokerage_trade ................. [OK in 76.20s]
14:55:47  5 of 43 START sql table model demo_bronze.brokerage_trade_history .............. [RUN]
25/01/19 14:55:47 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:56:52  5 of 43 OK created sql table model demo_bronze.brokerage_trade_history ......... [OK in 64.60s]
14:56:52  6 of 43 START sql table model demo_bronze.brokerage_watch_history .............. [RUN]
25/01/19 14:56:52 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:58:03  6 of 43 OK created sql table model demo_bronze.brokerage_watch_history ......... [OK in 71.91s]
14:58:03  7 of 43 START sql table model demo_bronze.crm_customer_mgmt .................... [RUN]
25/01/19 14:58:04 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
25/01/19 14:58:05 WARN package: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.
14:58:15  7 of 43 OK created sql table model demo_bronze.crm_customer_mgmt ............... [OK in 11.61s]
14:58:15  8 of 43 START sql table model demo_bronze.finwire_company ...................... [RUN]
25/01/19 14:58:15 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:58:19  8 of 43 OK created sql table model demo_bronze.finwire_company ................. [OK in 3.42s]
14:58:19  9 of 43 START sql table model demo_bronze.finwire_financial .................... [RUN]
25/01/19 14:58:19 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:59:46  9 of 43 OK created sql table model demo_bronze.finwire_financial ............... [OK in 86.98s]
14:59:46  10 of 43 START sql table model demo_bronze.finwire_security .................... [RUN]
25/01/19 14:59:46 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:59:49  10 of 43 OK created sql table model demo_bronze.finwire_security ............... [OK in 3.26s]
14:59:49  11 of 43 START sql table model demo_bronze.hr_employee ......................... [RUN]
25/01/19 14:59:49 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:59:53  11 of 43 OK created sql table model demo_bronze.hr_employee .................... [OK in 3.93s]
14:59:53  12 of 43 START sql table model demo_bronze.reference_date ...................... [RUN]
25/01/19 14:59:53 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:59:54  12 of 43 OK created sql table model demo_bronze.reference_date ................. [OK in 1.19s]
14:59:54  13 of 43 START sql table model demo_bronze.reference_industry .................. [RUN]
25/01/19 14:59:54 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:59:55  13 of 43 OK created sql table model demo_bronze.reference_industry ............. [OK in 0.84s]
14:59:55  14 of 43 START sql table model demo_bronze.reference_status_type ............... [RUN]
25/01/19 14:59:55 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:59:56  14 of 43 OK created sql table model demo_bronze.reference_status_type .......... [OK in 0.84s]
14:59:56  15 of 43 START sql table model demo_bronze.reference_tax_rate .................. [RUN]
25/01/19 14:59:56 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:59:57  15 of 43 OK created sql table model demo_bronze.reference_tax_rate ............. [OK in 0.86s]
14:59:57  16 of 43 START sql table model demo_bronze.reference_trade_type ................ [RUN]
25/01/19 14:59:57 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
14:59:57  16 of 43 OK created sql table model demo_bronze.reference_trade_type ........... [OK in 0.89s]
14:59:57  17 of 43 START sql table model demo_bronze.syndicated_prospect ................. [RUN]
25/01/19 14:59:58 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:00:04  17 of 43 OK created sql table model demo_bronze.syndicated_prospect ............ [OK in 6.47s]
15:00:04  18 of 43 START sql table model demo_silver.daily_market ........................ [RUN]
25/01/19 15:00:05 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:39:10  18 of 43 OK created sql table model demo_silver.daily_market ................... [OK in 2346.29s]
15:39:10  19 of 43 START sql table model demo_silver.employees ........................... [RUN]
25/01/19 15:39:11 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:39:15  19 of 43 OK created sql table model demo_silver.employees ...................... [OK in 4.32s]
15:39:15  20 of 43 START sql table model demo_silver.date ................................ [RUN]
25/01/19 15:39:15 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:39:16  20 of 43 OK created sql table model demo_silver.date ........................... [OK in 1.56s]
15:39:16  21 of 43 START sql table model demo_silver.companies ........................... [RUN]
25/01/19 15:39:17 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:39:22  21 of 43 OK created sql table model demo_silver.companies ...................... [OK in 6.38s]
15:39:22  22 of 43 START sql table model demo_silver.accounts ............................ [RUN]
25/01/19 15:39:23 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:39:38  22 of 43 OK created sql table model demo_silver.accounts ....................... [OK in 15.08s]
15:39:38  23 of 43 START sql table model demo_silver.customers ........................... [RUN]
25/01/19 15:39:38 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:39:49  23 of 43 OK created sql table model demo_silver.customers ...................... [OK in 10.63s]
15:39:49  24 of 43 START sql table model demo_silver.trades_history ...................... [RUN]
25/01/19 15:39:49 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:48:04  24 of 43 OK created sql table model demo_silver.trades_history ................. [OK in 495.51s]
15:48:04  25 of 43 START sql table model demo_gold.dim_broker ............................ [RUN]
25/01/19 15:48:05 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:48:10  25 of 43 OK created sql table model demo_gold.dim_broker ....................... [OK in 6.16s]
15:48:10  26 of 43 START sql table model demo_gold.dim_date .............................. [RUN]
25/01/19 15:48:11 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:48:12  26 of 43 OK created sql table model demo_gold.dim_date ......................... [OK in 1.75s]
15:48:12  27 of 43 START sql table model demo_gold.dim_company ........................... [RUN]
25/01/19 15:48:12 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:48:15  27 of 43 OK created sql table model demo_gold.dim_company ...................... [OK in 2.95s]
15:48:15  28 of 43 START sql table model demo_silver.financials .......................... [RUN]
25/01/19 15:48:16 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:49:57  28 of 43 OK created sql table model demo_silver.financials ..................... [OK in 102.21s]
15:49:57  29 of 43 START sql table model demo_silver.securities .......................... [RUN]
25/01/19 15:49:58 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:50:03  29 of 43 OK created sql table model demo_silver.securities ..................... [OK in 5.63s]
15:50:03  30 of 43 START sql table model demo_silver.cash_transactions ................... [RUN]
25/01/19 15:50:03 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:51:15  30 of 43 OK created sql table model demo_silver.cash_transactions .............. [OK in 72.17s]
15:51:15  31 of 43 START sql table model demo_gold.dim_customer .......................... [RUN]
25/01/19 15:51:16 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:51:34  31 of 43 OK created sql table model demo_gold.dim_customer ..................... [OK in 19.10s]
15:51:34  32 of 43 START sql table model demo_gold.dim_trade ............................. [RUN]
25/01/19 15:51:35 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
15:56:40  32 of 43 OK created sql table model demo_gold.dim_trade ........................ [OK in 305.75s]
15:56:40  33 of 43 START sql table model demo_silver.trades .............................. [RUN]
25/01/19 15:56:40 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
16:02:51  33 of 43 OK created sql table model demo_silver.trades ......................... [OK in 371.39s]
16:02:52  34 of 43 START sql table model demo_gold.dim_security .......................... [RUN]
25/01/19 16:02:52 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
16:02:56  34 of 43 OK created sql table model demo_gold.dim_security ..................... [OK in 4.63s]
16:02:56  35 of 43 START sql table model demo_silver.watches_history ..................... [RUN]
25/01/19 16:02:56 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
16:07:49  35 of 43 OK created sql table model demo_silver.watches_history ................ [OK in 293.33s]
16:07:49  36 of 43 START sql table model demo_gold.dim_account ........................... [RUN]
25/01/19 16:07:50 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
16:08:40  36 of 43 OK created sql table model demo_gold.dim_account ...................... [OK in 50.08s]
16:08:40  37 of 43 START sql table model demo_silver.holdings_history .................... [RUN]
25/01/19 16:08:40 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
16:16:51  37 of 43 OK created sql table model demo_silver.holdings_history ............... [OK in 491.85s]
16:16:51  38 of 43 START sql table model demo_silver.watches ............................. [RUN]
25/01/19 16:16:52 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
16:25:42  38 of 43 OK created sql table model demo_silver.watches ........................ [OK in 530.46s]
16:25:42  39 of 43 START sql table model demo_gold.fact_cash_transactions ................ [RUN]
25/01/19 16:25:42 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
16:31:09  39 of 43 OK created sql table model demo_gold.fact_cash_transactions ........... [OK in 327.43s]
16:31:09  40 of 43 START sql table model demo_gold.fact_trade ............................ [RUN]
25/01/19 16:31:10 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
16:46:07  40 of 43 OK created sql table model demo_gold.fact_trade ....................... [OK in 897.39s]
16:46:07  41 of 43 START sql table model demo_gold.fact_holdings ......................... [RUN]
25/01/19 16:46:07 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
17:12:36  41 of 43 OK created sql table model demo_gold.fact_holdings .................... [OK in 1588.78s]
17:12:36  42 of 43 START sql table model demo_gold.fact_watches .......................... [RUN]
25/01/19 17:12:36 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
17:18:41  42 of 43 OK created sql table model demo_gold.fact_watches ..................... [OK in 364.98s]
17:18:41  43 of 43 START sql table model demo_gold.fact_cash_balances .................... [RUN]
25/01/19 17:18:41 WARN ResolveSessionCatalog: A Hive serde table will be created as there is no table provider specified. You can set spark.sql.legacy.createHiveTableByDefault to false so that native data source table will be created instead.
17:22:48  43 of 43 OK created sql table model demo_gold.fact_cash_balances ............... [OK in 247.38s]
17:22:48  
17:22:48  Finished running 43 table models in 2 hours 32 minutes and 50.89 seconds (9170.89s).
17:22:48  
17:22:48  Completed successfully
17:22:48  
17:22:48  Done. PASS=43 WARN=0 ERROR=0 SKIP=0 TOTAL=43
Task exception was never retrieved
future: <Task finished name='Task-49' coro=<ScriptMagics.shebang.<locals>._handle_stream() done, defined at /usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py:211> exception=ValueError('Separator is not found, and chunk exceed the limit')>
Traceback (most recent call last):
  File "/usr/lib/python3.8/asyncio/streams.py", line 540, in readline
    line = await self.readuntil(sep)
  File "/usr/lib/python3.8/asyncio/streams.py", line 618, in readuntil
    raise exceptions.LimitOverrunError(
asyncio.exceptions.LimitOverrunError: Separator is not found, and chunk exceed the limit

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "/usr/local/lib/python3.8/dist-packages/IPython/core/magics/script.py", line 213, in _handle_stream
    line = (await stream.readline()).decode("utf8", errors="replace")
  File "/usr/lib/python3.8/asyncio/streams.py", line 549, in readline
    raise ValueError(e.args[0])
ValueError: Separator is not found, and chunk exceed the limit